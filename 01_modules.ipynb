{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_modules.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SiweiLuo/reinforcement-learning/blob/master/01_modules.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMH9cqVAJd0U",
        "colab_type": "code",
        "outputId": "9a5e575c-1c03-47e5-a3d7-fd93f45ce590",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn \n",
        "\n",
        "\n",
        "class OurModule(nn.Module):\n",
        "  def __init__(self,num_inputs,num_classes,dropout_prob=0.3):\n",
        "    super(OurModule,self).__init__()\n",
        "    self.pipe = nn.Sequential(\n",
        "        nn.Linear(num_inputs,5),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(5,20),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(20,num_classes),\n",
        "        nn.Dropout(p=dropout_prob),\n",
        "        nn.Softmax(dim=1)\n",
        "    )\n",
        "    \n",
        "  def forward(self,x):\n",
        "    return self.pipe(x) \n",
        "  \n",
        "  \n",
        "if __name__ == \"__main__\":\n",
        "  net = OurModule(num_inputs=2,num_classes=3)\n",
        "  print(net)\n",
        "  v = torch.FloatTensor([[2,3]])\n",
        "  out = net(v) \n",
        "  print(out) \n",
        "  print(\"Cuda's availability is %s\" % torch.cuda.is_available())\n",
        "  if torch.cuda.is_available():\n",
        "    print(\"Data from cuda: %s\" % out.to('cuda'))\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OurModule(\n",
            "  (pipe): Sequential(\n",
            "    (0): Linear(in_features=2, out_features=5, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=5, out_features=20, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=20, out_features=3, bias=True)\n",
            "    (5): Dropout(p=0.3)\n",
            "    (6): Softmax()\n",
            "  )\n",
            ")\n",
            "tensor([[0.3331, 0.2555, 0.4114]], grad_fn=<SoftmaxBackward>)\n",
            "Cuda's availability is False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vJUpAJ3KhuA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}